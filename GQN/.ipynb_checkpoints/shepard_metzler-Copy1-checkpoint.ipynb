{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural scene representation and rendering\n",
    "### https://deepmind.com/blog/neural-scene-representation-and-rendering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets: https://github.com/deepmind/gqn-datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets Translater: https://github.com/l3robot/gqn_datasets_translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import make_grid, save_image\n",
    "\n",
    "import os\n",
    "import datetime\n",
    "import random\n",
    "import math\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from pixyz.distributions import Normal\n",
    "from pixyz.losses import NLL, KullbackLeibler\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from gqn_dataset import GQNDataset, Scene, transform_viewpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pyramid(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Pyramid, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(7+3, 32, kernel_size=2, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=2, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, kernel_size=2, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 256, kernel_size=8, stride=8),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "\n",
    "    def forward(self, x, v):\n",
    "        # Broadcast\n",
    "        v = v.view(-1, 7, 1, 1).repeat(1, 1, 64, 64)\n",
    "        r = self.net(torch.cat((v, x)))\n",
    "        \n",
    "        return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tower(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Tower, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 256, kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(256, 256, kernel_size=2, stride=2)\n",
    "        self.conv3 = nn.Conv2d(256, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv4 = nn.Conv2d(128, 256, kernel_size=2, stride=2)\n",
    "        self.conv5 = nn.Conv2d(256+7, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv6 = nn.Conv2d(256+7, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv7 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv8 = nn.Conv2d(256, 256, kernel_size=1, stride=1)\n",
    "\n",
    "    def forward(self, x, v):\n",
    "        # Resisual connection\n",
    "        skip_in  = F.relu(self.conv1(x))\n",
    "        skip_out = F.relu(self.conv2(skip_in))\n",
    "\n",
    "        r = F.relu(self.conv3(skip_in))\n",
    "        r = F.relu(self.conv4(r)) + skip_out\n",
    "\n",
    "        # Broadcast\n",
    "        v = v.view(v.size(0), 7, 1, 1).repeat(1, 1, 16, 16)\n",
    "        \n",
    "        # Resisual connection\n",
    "        # Concatenate\n",
    "        skip_in = torch.cat((r, v), dim=1)\n",
    "        skip_out  = F.relu(self.conv5(skip_in))\n",
    "\n",
    "        r = F.relu(self.conv6(skip_in))\n",
    "        r = F.relu(self.conv7(r)) + skip_out\n",
    "        r = F.relu(self.conv8(r))\n",
    "\n",
    "        return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pool(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Pool, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 256, kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(256, 256, kernel_size=2, stride=2)\n",
    "        self.conv3 = nn.Conv2d(256, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv4 = nn.Conv2d(128, 256, kernel_size=2, stride=2)\n",
    "        self.conv5 = nn.Conv2d(256+7, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv6 = nn.Conv2d(256+7, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv7 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv8 = nn.Conv2d(256, 256, kernel_size=1, stride=1)\n",
    "        self.pool  = nn.AvgPool2d(16)\n",
    "\n",
    "    def forward(self, x, v):\n",
    "        # Resisual connection\n",
    "        skip_in  = F.relu(self.conv1(x))\n",
    "        skip_out = F.relu(self.conv2(skip_in))\n",
    "\n",
    "        r = F.relu(self.conv3(skip_in))\n",
    "        r = F.relu(self.conv4(r)) + skip_out\n",
    "\n",
    "        # Broadcast\n",
    "        v = v.view(v.size(0), 7, 1, 1).repeat(1, 1, 16, 16)\n",
    "        \n",
    "        # Resisual connection\n",
    "        # Concatenate\n",
    "        skip_in = torch.cat((r, v), dim=1)\n",
    "        skip_out  = F.relu(self.conv5(skip_in))\n",
    "\n",
    "        r = F.relu(self.conv6(skip_in))\n",
    "        r = F.relu(self.conv7(r)) + skip_out\n",
    "        r = F.relu(self.conv8(r))\n",
    "        \n",
    "        # Pool\n",
    "        r = self.pool(r)\n",
    "\n",
    "        return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2dLSTMCell(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1):\n",
    "        super(Conv2dLSTMCell, self).__init__()\n",
    "\n",
    "        kwargs = dict(kernel_size=kernel_size, stride=stride, padding=padding)\n",
    "        \n",
    "        in_channels += out_channels\n",
    "        \n",
    "        self.forget = nn.Conv2d(in_channels, out_channels, **kwargs)\n",
    "        self.input  = nn.Conv2d(in_channels, out_channels, **kwargs)\n",
    "        self.output = nn.Conv2d(in_channels, out_channels, **kwargs)\n",
    "        self.state  = nn.Conv2d(in_channels, out_channels, **kwargs)\n",
    "\n",
    "    def forward(self, input, states):\n",
    "        (cell, hidden) = states\n",
    "        input = torch.cat((hidden, input), dim=1)\n",
    "        \n",
    "        forget_gate = torch.sigmoid(self.forget(input))\n",
    "        input_gate  = torch.sigmoid(self.input(input))\n",
    "        output_gate = torch.sigmoid(self.output(input))\n",
    "        state_gate  = torch.tanh(self.state(input))\n",
    "\n",
    "        # Update internal cell state\n",
    "        cell = forget_gate * cell + input_gate * state_gate\n",
    "        hidden = output_gate * torch.tanh(cell)\n",
    "\n",
    "        return cell, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceCore(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(InferenceCore, self).__init__()\n",
    "        self.downsample_x = nn.Conv2d(3, 3, kernel_size=4, stride=4, padding=0, bias=False)\n",
    "        self.upsample_v = nn.ConvTranspose2d(7, 7, kernel_size=16, stride=16, padding=0, bias=False)\n",
    "        self.upsample_r = nn.ConvTranspose2d(256, 256, kernel_size=16, stride=16, padding=0, bias=False)\n",
    "        self.downsample_u = nn.Conv2d(128, 128, kernel_size=4, stride=4, padding=0, bias=False)\n",
    "        self.core = Conv2dLSTMCell(3+7+256+2*128, 128, kernel_size=5, stride=1, padding=2)\n",
    "        \n",
    "    def forward(self, x, v, r, c_e, h_e, h_g, u):\n",
    "        x = self.downsample_x(x)\n",
    "        v = self.upsample_v(v.view(-1, 7, 1, 1))\n",
    "        if r.size(2)!=h_e.size(2):\n",
    "            r = self.upsample_r(r)\n",
    "        u = self.downsample_u(u)\n",
    "        c_e, h_e = self.core(torch.cat((x, v, r, h_g, u), dim=1), (c_e, h_e))\n",
    "        \n",
    "        return c_e, h_e\n",
    "    \n",
    "class GenerationCore(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GenerationCore, self).__init__()\n",
    "        self.upsample_v = nn.ConvTranspose2d(7, 7, kernel_size=16, stride=16, padding=0, bias=False)\n",
    "        self.upsample_r = nn.ConvTranspose2d(256, 256, kernel_size=16, stride=16, padding=0, bias=False)\n",
    "        self.core = Conv2dLSTMCell(7+256+3, 128, kernel_size=5, stride=1, padding=2)\n",
    "        self.upsample_h = nn.ConvTranspose2d(128, 128, kernel_size=4, stride=4, padding=0, bias=False)\n",
    "        \n",
    "    def forward(self, v, r, c_g, h_g, u, z):\n",
    "        v = self.upsample_v(v.view(-1, 7, 1, 1))\n",
    "        if r.size(2)!=h_g.size(2):\n",
    "            r = self.upsample_r(r)\n",
    "        c_g, h_g =  self.core(torch.cat((v, r, z), dim=1), (c_g, h_g))\n",
    "        u = self.upsample_h(h_g) + u\n",
    "        \n",
    "        return c_g, h_g, u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inference(Normal):\n",
    "    def __init__(self):\n",
    "        super(Inference, self).__init__(cond_var=[\"h_e\"],var=[\"z\"])\n",
    "        self.eta_e = nn.Conv2d(128, 2*3, kernel_size=5, stride=1, padding=2)\n",
    "        \n",
    "    def forward(self, h_e):\n",
    "        mu, logvar = torch.split(self.eta_e(h_e), 3, dim=1)\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        \n",
    "        return {\"loc\": mu, \"scale\": std}\n",
    "    \n",
    "class Prior(Normal):\n",
    "    def __init__(self):\n",
    "        super(Prior, self).__init__(cond_var=[\"h_g\"],var=[\"z\"])\n",
    "        self.eta_pi = nn.Conv2d(128, 2*3, kernel_size=5, stride=1, padding=2)\n",
    "\n",
    "    def forward(self, h_g):\n",
    "        mu, logvar = torch.split(self.eta_pi(h_g), 3, dim=1)\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        \n",
    "        return {\"loc\": mu ,\"scale\": std}\n",
    "    \n",
    "class Generation(Normal):\n",
    "    def __init__(self):\n",
    "        super(Generation, self).__init__(cond_var=[\"u\", \"sigma\"],var=[\"x_q\"])\n",
    "        self.eta_g = nn.Conv2d(128, 3, kernel_size=1, stride=1, padding=0)\n",
    "        \n",
    "    def forward(self, u, sigma):\n",
    "        mu = self.eta_g(u)\n",
    "        \n",
    "        return {\"loc\": mu, \"scale\": sigma}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GQN(nn.Module):\n",
    "    def __init__(self, representation=\"pool\", L=12, shared_core=False):\n",
    "        super(GQN, self).__init__()\n",
    "        \n",
    "        # Number of generative layers\n",
    "        self.L = L\n",
    "        \n",
    "        self.shared_core = shared_core\n",
    "        \n",
    "        # Representation network\n",
    "        if representation==\"pyramid\":\n",
    "            self.phi = Pyramid()\n",
    "        elif representation==\"tower\":\n",
    "            self.phi = Tower()\n",
    "        elif representation==\"pool\":\n",
    "            self.phi = Pool()\n",
    "            \n",
    "        # Generation network\n",
    "        if shared_core:\n",
    "            self.inference_core = InferenceCore()\n",
    "            self.generation_core = GenerationCore()\n",
    "        else:\n",
    "            self.inference_core = nn.ModuleList([InferenceCore() for _ in range(L)])\n",
    "            self.generation_core = nn.ModuleList([GenerationCore() for _ in range(L)])\n",
    "        \n",
    "        # Distribution\n",
    "        self.pi = Prior()\n",
    "        self.q = Inference()\n",
    "        self.g = Generation()\n",
    "\n",
    "    # EstimateELBO\n",
    "    def forward(self, x, v, v_q, x_q, sigma):\n",
    "        B, M, *_ = x.size()\n",
    "        \n",
    "        # Scene encoder\n",
    "        r = x.new_zeros((B, 256, 16, 16))\n",
    "        for k in range(M):\n",
    "            r_k = self.phi(x[:, k], v[:, k])\n",
    "            r += r_k\n",
    "            \n",
    "        # Generator initial state\n",
    "        c_g = x.new_zeros((B, 128, 16, 16))\n",
    "        h_g = x.new_zeros((B, 128, 16, 16))\n",
    "        u = x.new_zeros((B, 128, 64, 64))\n",
    "\n",
    "        # Inference initial state\n",
    "        c_e = x.new_zeros((B, 128, 16, 16))\n",
    "        h_e = x.new_zeros((B, 128, 16, 16))\n",
    "                \n",
    "        elbo = 0\n",
    "        for l in range(self.L):\n",
    "            # Inference state update\n",
    "            if self.shared_core:\n",
    "                c_e, h_e = self.inference_core(x_q, v_q, r, c_e, h_e, h_g, u)\n",
    "            else:\n",
    "                c_e, h_e = self.inference_core[l](x_q, v_q, r, c_e, h_e, h_g, u)\n",
    "            \n",
    "            # Posterior sample\n",
    "            z = self.q.sample({\"h_e\": h_e}, reparam=True)[\"z\"]\n",
    "            \n",
    "            # ELBO KL contribution update\n",
    "            elbo -= KullbackLeibler(self.q, self.pi).estimate({\"h_e\": h_e, \"h_g\": h_g})\n",
    "            \n",
    "            # Generator state update\n",
    "            if self.shared_core:\n",
    "                c_g, h_g, u = self.generation_core(v_q, r, c_g, h_g, u, z)\n",
    "            else:\n",
    "                c_g, h_g, u = self.generation_core[l](v_q, r, c_g, h_g, u, z)\n",
    "                \n",
    "        # ELBO likelihood contribution update\n",
    "        elbo -= NLL(self.g).estimate({\"u\":u, \"sigma\":sigma, \"x_q\": x_q})\n",
    "\n",
    "        return elbo\n",
    "    \n",
    "    def generate(self, x, v, v_q):\n",
    "        B, M, *_ = x.size()\n",
    "        \n",
    "        # Scene encoder\n",
    "        r = x.new_zeros((B, 256, 16, 16))\n",
    "        for k in range(M):\n",
    "            r_k = self.phi(x[:, k], v[:, k])\n",
    "            r += r_k\n",
    "\n",
    "        # Initial state\n",
    "        c_g = x.new_zeros((B, 128, 16, 16))\n",
    "        h_g = x.new_zeros((B, 128, 16, 16))\n",
    "        u = x.new_zeros((B, 128, 64, 64))\n",
    "        \n",
    "        for l in range(self.L):\n",
    "            # Prior sample\n",
    "            z = self.pi.sample({\"h_g\": h_g})[\"z\"]\n",
    "            \n",
    "            # State update\n",
    "            if self.shared_core:\n",
    "                c_g, h_g, u = self.generation_core(v_q, r, c_g, h_g, u, z)\n",
    "            else:\n",
    "                c_g, h_g, u = self.generation_core[l](v_q, r, c_g, h_g, u, z)\n",
    "            \n",
    "        x_q_hat = self.g.sample_mean({\"u\": u, \"sigma\": 0})\n",
    "\n",
    "        return torch.clamp(x_q_hat, 0, 1)\n",
    "    \n",
    "    def kl_divergence(self, x, v, v_q, x_q):\n",
    "        B, M, *_ = x.size()\n",
    "\n",
    "        # Scene encoder\n",
    "        r = x.new_zeros((B, 256, 16, 16))\n",
    "        for k in range(M):\n",
    "            r_k = self.phi(x[:, k], v[:, k])\n",
    "            r += r_k\n",
    "            \n",
    "        # Generator initial state\n",
    "        c_g = x.new_zeros((B, 128, 16, 16))\n",
    "        h_g = x.new_zeros((B, 128, 16, 16))\n",
    "        u = x.new_zeros((B, 128, 64, 64))\n",
    "\n",
    "        # Inference initial state\n",
    "        c_e = x.new_zeros((B, 128, 16, 16))\n",
    "        h_e = x.new_zeros((B, 128, 16, 16))\n",
    "                \n",
    "        kl = 0\n",
    "        for l in range(self.L):\n",
    "            # Inference state update\n",
    "            if self.shared_core:\n",
    "                c_e, h_e = self.inference_core(x_q, v_q, r, c_e, h_e, h_g, u)\n",
    "            else:\n",
    "                c_e, h_e = self.inference_core[l](x_q, v_q, r, c_e, h_e, h_g, u)\n",
    "            \n",
    "            # Posterior sample\n",
    "            z = self.q.sample({\"h_e\": h_e}, reparam=True)[\"z\"]\n",
    "            \n",
    "            # KL divergence\n",
    "            kl += KullbackLeibler(self.q, self.pi).estimate({\"h_e\": h_e, \"h_g\": h_g})\n",
    "            \n",
    "            # Generator state update\n",
    "            if self.shared_core:\n",
    "                c_g, h_g, u = self.generation_core(v_q, r, c_g, h_g, u, z)\n",
    "            else:\n",
    "                c_g, h_g, u = self.generation_core[l](v_q, r, c_g, h_g, u, z)\n",
    "\n",
    "        return kl\n",
    "    \n",
    "    def reconstruct(self, x, v, v_q, x_q):\n",
    "        B, M, *_ = x.size()\n",
    "\n",
    "        # Scene encoder\n",
    "        r = x.new_zeros((B, 256, 16, 16))\n",
    "        for k in range(M):\n",
    "            r_k = self.phi(x[:, k], v[:, k])\n",
    "            r += r_k\n",
    "            \n",
    "        # Generator initial state\n",
    "        c_g = x.new_zeros((B, 128, 16, 16))\n",
    "        h_g = x.new_zeros((B, 128, 16, 16))\n",
    "        u = x.new_zeros((B, 128, 64, 64))\n",
    "\n",
    "        # Inference initial state\n",
    "        c_e = x.new_zeros((B, 128, 16, 16))\n",
    "        h_e = x.new_zeros((B, 128, 16, 16))\n",
    "                \n",
    "        for l in range(self.L):\n",
    "            # Inference state update\n",
    "            if self.shared_core:\n",
    "                c_e, h_e = self.inference_core(x_q, v_q, r, c_e, h_e, h_g, u)\n",
    "            else:\n",
    "                c_e, h_e = self.inference_core[l](x_q, v_q, r, c_e, h_e, h_g, u)\n",
    "            \n",
    "            # Posterior sample\n",
    "            z = self.q.sample({\"h_e\": h_e}, reparam=True)[\"z\"]\n",
    "            \n",
    "            # Generator state update\n",
    "            if self.shared_core:\n",
    "                c_g, h_g, u = self.generation_core(v_q, r, c_g, h_g, u, z)\n",
    "            else:\n",
    "                c_g, h_g, u = self.generation_core[l](v_q, r, c_g, h_g, u, z)\n",
    "                \n",
    "        x_q_rec = self.g.sample_mean({\"u\": u, \"sigma\": 0})\n",
    "\n",
    "        return torch.clamp(x_q_rec, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_batch(x_data, v_data, D, M=None, seed=None):\n",
    "    random.seed(seed)\n",
    "    \n",
    "    if D == \"Room\":\n",
    "        K = 5\n",
    "    elif D == \"Jaco\":\n",
    "        K = 7\n",
    "    elif D == \"Labyrinth\":\n",
    "        K = 20\n",
    "    elif D == \"Shepard-Metzler\":\n",
    "        K = 15\n",
    "\n",
    "    # Sample number of views\n",
    "    if not M:\n",
    "        M = random.randint(1, K)\n",
    "\n",
    "    context_idx = random.sample(range(x_data.size(1)), M)\n",
    "    query_idx = random.randint(0, x_data.size(1)-1)\n",
    "\n",
    "    # Sample view\n",
    "    x, v = x_data[:, context_idx], v_data[:, context_idx]\n",
    "    # Sample query view\n",
    "    x_q, v_q = x_data[:, query_idx], v_data[:, query_idx]\n",
    "    \n",
    "    return x, v, x_q, v_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning rate at training step s with annealing \n",
    "class AnnealingStepLR(_LRScheduler):\n",
    "    def __init__(self, optimizer, mu_i=5e-4, mu_f=5e-5, n=1.6e6):\n",
    "        self.mu_i = mu_i\n",
    "        self.mu_f = mu_f\n",
    "        self.n = n\n",
    "        super(AnnealingStepLR, self).__init__(optimizer)\n",
    "\n",
    "    def get_lr(self):\n",
    "        return [max(self.mu_f + (self.mu_i - self.mu_f) * (1.0 - self.last_epoch / self.n), self.mu_f) for base_lr in self.base_lrs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/2000000 [00:21<12116:05:10, 21.81s/it]"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-45748775d07c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;31m# Compute empirical ELBO gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m     \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0melbo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;31m# Update parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/autograd/function.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_cls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/parallel/_functions.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(ctx, *grad_outputs)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mgrad_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mReduceAddCoalesced\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mgrad_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/parallel/_functions.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, destination, num_inputs, *grads)\u001b[0m\n\u001b[1;32m     39\u001b[0m         grads = [grads[i:i + num_inputs]\n\u001b[1;32m     40\u001b[0m                  for i in range(0, len(grads), num_inputs)]\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcomm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_add_coalesced\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestination\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/cuda/comm.py\u001b[0m in \u001b[0;36mreduce_add_coalesced\u001b[0;34m(inputs, destination, buffer_size)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mchunks\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mitrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0mflat_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_flatten_dense_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchunks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0mflat_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreduce_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestination\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_unflatten_dense_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_reorder_tensors_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_order\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/cuda/comm.py\u001b[0m in \u001b[0;36mreduce_add\u001b[0;34m(inputs, destination)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnccl_root\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"reduce_add expects destination to be on the same GPU with one of the tensors\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdestination\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize_as_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnccl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdestination\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Dataset directory\n",
    "train_data_dir = '/workspace/dataset/shepard_metzler_7_parts-torch/train'\n",
    "test_data_dir = '/workspace/dataset/shepard_metzler_7_parts-torch/test'\n",
    "\n",
    "# Number of workers to load data\n",
    "num_workers = 0\n",
    "\n",
    "# Log\n",
    "log_interval_num = 100\n",
    "save_interval_num = 10000\n",
    "dir_name = str(datetime.datetime.now())\n",
    "log_dir = '/workspace/logs/'+ dir_name\n",
    "os.mkdir(log_dir)\n",
    "os.mkdir(log_dir+'/models')\n",
    "os.mkdir(log_dir+'/runs')\n",
    "\n",
    "# TensorBoardX\n",
    "writer = SummaryWriter(log_dir=log_dir+'/runs')\n",
    "\n",
    "# Dataset\n",
    "train_dataset = GQNDataset(root_dir=train_data_dir, target_transform=transform_viewpoint)\n",
    "test_dataset = GQNDataset(root_dir=test_data_dir, target_transform=transform_viewpoint)\n",
    "D = \"Shepard-Metzler\"\n",
    "\n",
    "# Pixel standard-deviation\n",
    "sigma_i, sigma_f = 2.0, 0.7\n",
    "sigma = sigma_i\n",
    "\n",
    "# Number of scenes over which each weight update is computed\n",
    "B = 36\n",
    "\n",
    "# Number of generative layers\n",
    "L = 8\n",
    "\n",
    "# Maximum number of training steps\n",
    "S_max = 2*10**6\n",
    "\n",
    "# Define model\n",
    "model = GQN().to(device)\n",
    "model = nn.DataParallel(model)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-4, betas=(0.9, 0.999), eps=1e-08)\n",
    "scheduler = AnnealingStepLR(optimizer, mu_i=5e-4, mu_f=5e-5, n=1.6e6)\n",
    "\n",
    "kwargs = {'num_workers':num_workers, 'pin_memory': True} if torch.cuda.is_available() else {}\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=B, shuffle=True, **kwargs)\n",
    "test_loader = DataLoader(test_dataset, batch_size=B, shuffle=True, **kwargs)\n",
    "    \n",
    "train_iter = iter(train_loader)\n",
    "x_data_test, v_data_test = next(iter(test_loader))\n",
    "\n",
    "# Training Iterations\n",
    "for t in tqdm(range(S_max)):\n",
    "    try:\n",
    "        x_data, v_data = next(train_iter)\n",
    "    except StopIteration:\n",
    "        train_iter = iter(train_loader)\n",
    "        x_data, v_data = next(train_iter)\n",
    "        \n",
    "    x_data = x_data.to(device)\n",
    "    v_data = v_data.to(device)\n",
    "    x, v, x_q, v_q = sample_batch(x_data, v_data, D)\n",
    "    elbo = model(x, v, v_q, x_q, sigma)\n",
    "        \n",
    "    # logs\n",
    "    writer.add_scalar('train_loss', -elbo.mean(), t)\n",
    "                \n",
    "    with torch.no_grad():\n",
    "        # write logs to tensorboard\n",
    "        if t % log_interval_num == 0:\n",
    "            x_data_test = x_data_test.to(device)\n",
    "            v_data_test = v_data_test.to(device)\n",
    "                \n",
    "            x_test, v_test, x_q_test, v_q_test = sample_batch(x_data_test, v_data_test, D, M=3, seed=0)\n",
    "            elbo_test = model(x_test, v_test, v_q_test, x_q_test, sigma)\n",
    "            kl_test = model.module.kl_divergence(x_test, v_test, v_q_test, x_q_test)\n",
    "            x_q_rec_test = model.module.reconstruct(x_test, v_test, v_q_test, x_q_test)\n",
    "            x_q_hat_test = model.module.generate(x_test, v_test, v_q_test)\n",
    "                        \n",
    "            writer.add_scalar('test_loss', -elbo_test.mean(), t)\n",
    "            writer.add_scalar('test_kl', kl_test.mean(), t)\n",
    "            writer.add_image('test_ground_truth', make_grid(x_q_test, 6, pad_value=1), t)\n",
    "            writer.add_image('test_reconstruction', make_grid(x_q_rec_test, 6, pad_value=1), t)\n",
    "            writer.add_image('test_generation', make_grid(x_q_hat_test, 6, pad_value=1), t)\n",
    "            \n",
    "        if t % save_interval_num == 0:\n",
    "            torch.save(model.state_dict(), log_dir + \"/models/model-{}.pt\".format(t))\n",
    "    \n",
    "    # Compute empirical ELBO gradients\n",
    "    (-elbo.mean()).backward()\n",
    "        \n",
    "    # Update parameters\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "        \n",
    "    # Update optimizer state\n",
    "    scheduler.step()\n",
    "            \n",
    "    # Pixel-variance annealing\n",
    "    sigma = max(sigma_f + (sigma_i - sigma_f)*(1 - t/(2e5)), sigma_f)\n",
    "\n",
    "torch.save(model.state_dict(), log_dir + \"/models/model-final.pt\")  \n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
